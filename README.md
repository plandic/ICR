# ICR

## 2023/05/27
- TabPFNというテーブルデータのためのTransformerモデル
- 論文では「小さな表形式データに対して1秒以内に教師あり分類タスクを実行でき，ハイパーパラメータのチューニングがいらない高精度のモデル」
- 精度としてはOpenML-CC18というデータセットの中の30個のデータセットでGBDTの性能を上回ったほか，AutoMLに対して同等の精度を70倍の速度で達成した
- PFN(Prior-Data Fitted Networks)をもとに構築されており，ベイジアンニューラルネットワークと構造的因果モデルに基づき表形式データの根底にある複雑な特徴量の依存性と潜在的な因果構造をモデル化する事前分布を作り出す
- 1回のフォワードパスで新しい事前分布を確率的に推定するように事前に訓練されたTransformerで，小規模の分類タスク(サンプル数<1000,特徴量数100，10クラス)を1秒未満で解き，高い精度を達成しました
- ニューラルネットワークやGBDTの帰納バイアスはL2正則化や木の深さの調整などのパラメータに依存しますが，TabPFNではそのような設定は不要
- XGBoost,LightGBM，CatBoostなどの分類アルゴリズムより精度が高く，AutoMLが5〜60分で達成できる性能と同等の性能を示した
![image](https://github.com/plandic/ICR/assets/34090657/fda1920a-d90a-4a9e-86a8-73c325082474)

## 2023/05/28
- drop_cols = ['AY','BC', 'BZ','CL']
- ![image](https://github.com/plandic/ICR/assets/34090657/5bbb3775-6586-40b7-8589-75aa59913faf)
